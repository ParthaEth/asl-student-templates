\chapter{Introduction}
\label{sec:introduction}

Visual inertial mapping (VI-mapping) is an interesting and challenging problem, that has received several decade of research and exploration. With application in disaster response, city planing, indoor navigation, accurate navigation system, etc. visual inertial mapping as part of Simultaneous Localization and Mapping is one of the cutting edge research fields that find immediate deployment in real systems. On the other hand it also intrigues pure academic and research interests independent of its real applications as it asks for real time multi-sensor data fusion.

\section{Motivation and Objectives}
Inertial measurement units (IMUs) are high bandwidth (very frequent measurements possible) interoceptive sensor that provides frequent but noisy measurement of movement of a body. High fidelity motion tracking with only IMU measurements is hard, especially for long time. A vision system however is relatively low frequency but very reliable (low noise) exteroceptive measurement. The image of a camra tends to become blurred at high speed maneuvers reducing signal to noise ratio in the output, but during fast random movement usually the signal to noise ratio of the IMU is improved. This complementary nature makes an IMU camera system suitable for wide range of applications. Visual-Inertial Localization and Mapping is particularly interesting in GPS denied work-spaces and in situations which require more accuracy than a GPS system can provide. There are three popular ways of performing visual inertial mapping. As is evident such maps grow with time and hence the growth of computational complexity is unavoidable. Hence a common objective of all the methods to perform VI-mapping is to keep the problem tractable for the longest possible time.
\begin{itemize}
  \item \textbf{EKF Batch Optimization :} 
  In this paradigm the problem is set as a growing state Extended Kalman Filter (EKF). All the robot pose and landmarks observed by the camera is added to the state and incremental update is performed at each time step. Clearly the complexity is squared in number of both key points (landmarks) observed and robot poses (vertices) as the covariance matrix grows proportional to this number and it is necessary to invert it in each time step. 
  \item \textbf{Incremental Batch Optimization :} 
  In Incremental Batch optimization methods an optimization problem is solved at every time step. This optimization contain all the observed landmarks and all the attained robot poses and is solved with all the available measurements till current time. Complexity of this method is cubic in number of robot poses and number of landmarks observed.
  \item \textbf{Sliding Window Optimization and BA :} 
  The two methods discussed above quickly becomes infeasible for real time operation, but for autonomous robot navigation pose estimation is necessary at all time. In order to restrict the complexity from growing Sliding Window Optimization methods consider only past few poses and marginalizes the information from past poses that are beyond the window width. Clearly because at any point there is constant number of parameter the complexity does not grow with time. The price that is paid in order to achieve feasibility though is that this method can not loop close on its own. Hence in order to generate globally consistent map a separate Bundle Adjustment routine is run time to time, which is nothing but a complete batch optimization of poses and landmarks with all available measurements.
\end{itemize}

Almost all modern SLAM systems implement method three, i.e. it consists of a Sliding Window Estimator and a Bundle Adjustment routine running in parallel. The bundle adjustment although runs offline (i.e. not real time) eventually becomes computationally infeasible. This necessitates a way to reduce complexity of bundle adjustment. Key-framing is one such method but it suffers from degraded quality. CKLAM extends key-framing method which achieved improved performance while being reasonably close in computational complexity. Yet it suffers from computation penalty in multi-agent mapping scenario and in case of high drift corruption that follow loop closure. RCKLAM proposed in this thesis overcomes these while maintaining the quality of the solution.

\section{Overview of Related Work}
This section is dedicated to the literature review of the most common systems that addresses the issue of VI-mapping. Here we shall point out the advantages and disadvantages of these and contrast them with both CKLAM and RCKLAM method.
 
As introduced earlier in order for autonomous mobile robots to be able to navigate in large environment over long period of time, it is necessary to have a technique that can track accurately the robot pose relative to the environment. Since often the environment is not mapped a priory, it is necessary to perform simultaneous localization and mapping (SLAM). The problem of SLAM is inherently computationally intensive. This is evident from the study of available and most popular techniques. Minimum Mean Squared Error (MMSE)\cite{EkFSLAM} implemented with an Extended Kalman Filter has complexity of $O(N^2)$ where $N$ is the number of landmarks in the map. Similarly a Maximum A Posteriori (MAP) estimator\cite{FULL-BA-BASED} has complexity of $O([K+N]^3)$, where $K$ is the number of robot poses in the map and $N$ as before is the number of landmarks in the map. Although existing MAP-based solvers for SLAM such as $\sqrt(SLAM)$ \cite{FULL-BA-BASED}, $g^2o$\cite{g2o}, SPA \cite{spaBYkonolige} efficiently exploits the sparsity in the problems to reduce complexity. But large enough map and frequent loop closure eventually renders the algorithm inappropriate for real time operation.

It has been already introduced that the most popular methods to SLAM can broadly be divided into three categories. Now, let us take a more concrete look at them and also let us find some advantages and disadvantages associated with them. Approaches such as iSLAM\cite{Kaess08thesis} iSLAM2\cite{Kaess01022012} incrementally solve an optimization problem containing all the robot poses along the trajectory, landmarks and measurements. Clearly the complexity in such approaches grows with time as the number of robot poses, landmarks and measurements increase. Although by exploiting sparsity these methods can work for reasonable period of time, frequent loop closure and prolonged usage eventually prohibits real-time operation of the algorithm. These approaches form the first category.

The second category of approaches such as the ones discussed in \cite {Sibley:2010, 4801600} have a fixed lag smoother as common part. In this approach the computational cost is maintained constant by marginalizing information from the frames outside the width of the sliding window. This makes the information matrix dense and hence the computational complexity becomes cubic in the number of poses considered in the window forcing the number of poses in the sliding window rather small. More over since this approach is unable to loop close it drifts faster than other methods. Often an offline bundle adjustment algorithm is run to perform loop closure and to achieve globally consistent maps.

The third category of methods such as PTAM \cite{klein07parallel}, FrameSLAM \cite{4648456} and view based methods \cite {Konolige01072010, 6630556}, take the approach of key framing. In this paradigm poses along the robot path is assigned either to be a key-frame or a non-key-frame. All the information available from the non-key-frames is discarded. Hence it is able to maintain sparsity, which lets it achieve computational efficiency at the cost of reduced accuracy. 

In \cite{CKLAM}, Esha D. Nerurkar, et al. developed `Constrained Key-frame Localization and Mapping' (CKLAM) technique. In this technique information from non-key-frames is marginalized and yet the technique is able to maintain sparsity. This way CKLAM achieves higher computational performance and higher quality of map at the same time. During this thesis a realization of this work has been achieved and it has been thoroughly tested with real and simulated maps. 

\section{Contributions}
Although CKLAM achieves solution to some of the key problems faced in large scale SLAM problem it suffers from the following drawbacks. CKLAM by projecting information from non-key-frame poses onto the key-frames generate expected mean pose, covariance and a gradient for every key-frame pair. This causes generation of constraints to the pose of key-frames in global coordinate frame, which is not a drawback when an area is explored by a single agent. But in multiple agent based mapping use cases since the frame of reference of each agent is not aligned or they do not use same global frame it is necessary to change frame of reference on the fly of large map segments. It also becomes necessary to recompute the CKLAM information at this point, if any such segment already had them. As CKLAM approximates the true cost function with a quadratic approximation, the trust region of convergence is limited. This imposes a constraint when loop closure constraints tries to move a long drifting map segment by a large amount. It can be readily seen that the problem lies in the design of CKLAM, viz. it tries to represent integrated noise/information as independent Gaussian distribution. Hence a better formulation of CKLAM would be to project the information from non-key-frames onto the relative transformation between two consecutive key-frame poses rather than projecting them directly on the key-frame poses. The main contributions of this thesis work are as follows. In contrast to intractable full bundle adjustment a key-frame based technique has been implemented. The technique in contrast to traditional approaches considers the information from non-key-frames. A few drawbacks as described above has been identified in the CKLAM formulation. An extension Relative CKLAM (RCKLAM) has been proposed which has been shown to overcome the problems identified. By design RCKLAM's computational complexity matches that of CKLAM. 

\section{Thesis Outline}
The contribution of this thesis can be broadly divided into two categories. First is the implementation of the famous CKLAM technique. In this context we shall establish a firm mathematical basis which we hope will make the work flow of CKLAM more intuitive to follow. Besides this since the second contribution of this thesis builds on the concept of CKLAM it would be easy to follow that as well. In chapter \ref {sec:CKLAM} we shall discuss the theory behind CKLAM and also derive the most important equations from first principle. Here we shall also find the important issues with CKLAM that we would like to address. In chapter \ref{sec:RCKLAM} we will look at the foundation of Relative-CKLAM (RCKLAM) that is proposed in this theses to solve the problems identified in chapter \ref{sec:CKLAM}. Finally in chapter \ref{chap:ExptAndResults} the results of different experiments on both real and simulated map will be presented.
