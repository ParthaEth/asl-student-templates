\chapter{Introduction}
\label{sec:introduction}
%\chapter{Einleitung}
%\label{sec:einleitung}

In order for autonomous mobile robots to be able to navigate in large environment over long period of time, it is necessary to have a technique that can track accurately the robot pose relative to the environment. Since often the environment is not mapped a priory, it is necessary to perform simultaneous localization and mapping (SLAM). The problem of SLAM is inherently computationally intensive. This is evident from the study of available and most popular techniques. Minimum Mean Squared Error (MMSE)\cite{EkFSLAM} implemented with an extended Kalman filter has complexity of $O(N^2)$ where $N$ is the number of landmarks in the map. Similarly a Maximum A Posteriori (MAP) estimator\cite{FULL-BA-BASED} has complexity of $O([K+N]^3)$, where $K$ is the number of robot poses in the map and $N$ as before is the nmber of landmarks in the map. Although existing MAP-besed solvers for SLAM such as $\sqrt(SLAM)$ \cite{FULL-BA-BASED}, $g^2o$\cite{}, SPA \cite{} efficiently exploits the sparsity in the problems to reduce complexity. Large enough map and frequent loop closure eventually renders the algorithm inappropriate for real time operation.

The most popular methods to SLAM can broadly be divided into three categories. Approaches such as iSLAM\cite{} iSLAM2\cite{} incrementally solve an optimization problem containing all the robot poses along the trajectory, landmarks and measurements. Clearly the complexity in such approaches grows with time as the number of robot poses, landmarks and measurements increase. Although by exploiting sparsity these methods can work for reasonable period of time, frequent loop closure and prolonged usage eventually prohibits real-time operation of the algorithm. These approaches form the first category.

The second category of approaches such as the ones discussed in \cite {} have a fixed lag smoother as common part. In this approach the computational cost is maintained constant by marginalizing information from the frames outside the width of the sliding window. This makes the information matrix dense and hence the computational complexity becomes cubic in the number of poses considered in the window forcing the number of poses in the sliding window rather small. More over since this approach is unable to loop close it drifts faster than other methods. Often an offline bundle adjustment algorithm is run to perform loop closure and to achieve globally consistent maps.

The third category of methods such as PTAM \cite{}, FrameSLAM \cite{} and view based methods \cite {}, take the approach of key framing. In this paradigm poses along the robot path is assigned either to be a keyframe or a non-keyframe. All the information available from the non-keyframes is discarded. Hence it is able to maintain sparsity, which lets it achieve computational efficiency at the cost of reduced accuracy. 

In \cite{}, Esha D. Nerurkar, et al. developed `Constrained Keyframe Localization and Mapping' (CKLAM) technique. In this technique information from non-keyframes is marginalized and yet the technique is able to maintain sparsity. This way CKLAM achieves higher performance and higher quality of map at the same time. During this thesis a realization of this work has been achieved and it has been thoroughly tested with real and simulated maps. Although CKLAM achieves solution to some of the key problems faced in large scale SLAM problem it suffers from the following drawbacks. CKLAM by projecting information from non-keyframe poses onto the keyframes generate expected mean pose, covariance and a gradient for every keyframe pair. This causes generation of constraints to the pose of keyframes in global co-ordinate frame, which is not a drawback when an area is explored by a single agent. But in multiple agent based mapping use cases since the frame of reference of each agent is not aligned or they do not use same global frame it is necessary to change frame of reference on the fly to large map segments. It also becomes necessary to recompute the CKLAM information at this point if any such segment already had them. As CKLAM approximates the true cost function with a quadratic approximation, the trust region of convergence is limited. This imposes a constraint when loop closure constraints tries to move a long drifting map segment by a large amount. It can be readily seen that the problem lies in the design of CKLAM, viz. it tries to represent integrated noise/information as independent Gaussian distribution. Hence a better formulation of CKLAM would be to project the information from non-keyframes onto the relative transformation between two consecutive keyframe poses rather than projecting them directly on the keyframe poses. The main contributions of this thesis work are as follows. In contrast to intractable full bundle adjustment a keyframe based technique has been implemented. The technique in contrast to traditional approaches considers the information from non-keyframes. A few drawbacks as described above has been identified in the CKLAM formulation. An extension Relative CKLAM (RCKLAM) has been proposed which has been shown to overcome the problems identified. By design RCKLAM's computational complexity matches that of CKLAM. 

