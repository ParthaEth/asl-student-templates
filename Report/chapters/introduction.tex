\chapter{Introduction}
\label{sec:introduction}

Visual inertial mapping (VI-mapping) is an interesting and challenging problem, that has received several decades of research and exploration. With applications in disaster response, city planing, indoor navigation, accurate navigation systems, etc. VI-mapping as part of Simultaneous Localization and Mapping (SLAM) is one of the cutting edge research fields that find immediate deployment in real systems. On the other hand it also intrigues pure academic and research interests independent of its real applications as it asks for real-time multi-sensor data fusion.

\section{Motivation and Objectives}
Tracking high speed maneuvers in real time and over long duration is particularly challenging because of the necessity of sensing mechanism that depicts excellent signal to noise ratio and at the same time produces frequent measurements. Often these two criterion pose themselves as conflicting to one another. Inertial measurement units (IMUs) are high bandwidth (frequent measurements) interoceptive sensors that provide frequent but noisy measurements of movement of a body. High fidelity motion tracking with only IMU measurements is hard, especially for a long time. A vision system however, is relatively low frequency but very reliable (low noise) exteroceptive measurements. The image of a camera tends to become blurred at high speed maneuvers reducing signal to noise ratio in the output, but during fast random movements the signal to noise ratio of the IMU is improved. This complementary nature makes an IMU-camera system suitable for wide range of applications. Visual-Inertial Localization and Mapping is particularly interesting in GPS denied work-spaces and in situations which require more accuracy than a GPS system can provide. As is evident such maps grow with time and hence the growth of computational complexity is unavoidable. Hence a common objective of all the methods to perform VI-mapping is to keep the problem tractable for the longest possible time. There are three popular ways of performing visual inertial mapping.
\begin{enumerate}
  \item \textbf{EKF Batch Optimization :} 
  In this paradigm the problem is set as a growing state Extended Kalman Filter (EKF). All the robot poses and landmarks observed by the camera are added to the state and an incremental update is performed at each time step. Clearly the complexity is squared in the number of both key points (landmarks) observed and robot poses (vertices), as the covariance matrix grows proportional to this number and it is necessary to invert it in each time step. 
  \item \textbf{Incremental Batch Optimization :} 
  In Incremental Batch Optimization methods an optimization problem is solved at every time step. This optimization contains all the observed landmarks and all the attained robot poses and is solved with all the available measurements available till current time. The complexity of this method has a cubic dependency with the number of the robot poses and number of the landmarks observed.
  \item \textbf{Sliding Window Optimization and BA :} 
  The two methods discussed above quickly become infeasible for real time operation, but for autonomous robot navigation pose estimation is necessary at all times. In order to restrict the complexity from growing, Sliding Window Optimization methods consider only a few past poses and marginalizes the information from past poses that are beyond the window width. Clearly since at any point there is a constant number of parameters the complexity does not grow with time. The price that is paid in order to achieve feasibility though, is the inability of this method to loop close on its own besides having lower accuracy. Hence in order to generate globally consistent maps, a separate BA routine is run from time to time, which is nothing but a complete batch optimization of poses and landmarks with all available measurements.
\end{enumerate}

Almost all modern SLAM systems implement method three, i.e. it consists of a Sliding Window Estimator and a BA routine running in parallel. Although the bundle adjustment runs offline (i.e. not in real time), it eventually becomes computationally infeasible. This necessitates a way to reduce complexity of BA. Key-framing is one such method but it suffers from degraded quality. CKLAM extends the key-framing method which achieves improved performance while being reasonably close in computational complexity. However it suffers from a computation penalty in multi-agent mapping scenarios and in cases when high drift corruption is corrected by loop closure. Reclative CKLAM (RCKLAM) proposed in this thesis, overcomes these limitations, while maintaining the quality of the solution.

\section{Overview of Related Work}
This section is dedicated to the literature review of the most common systems that address the issue of VI-mapping. Here we shall point out the advantages and disadvantages of these and contrast them with both CKLAM and RCKLAM method.
 
As introduced earlier, in order for autonomous mobile robots to be able to navigate in large environments over a long period of time, it is necessary to have a technique that can accurately track the robot pose relative to the environment. Since often the environment is not mapped a priori, it is necessary to perform SLAM. The problem of SLAM is inherently computationally intensive. This is evident from the study of the most popular techniques. Minimum Mean Squared Error (MMSE)\cite{EkFSLAM} implemented with an Extended Kalman Filter (EKF) has complexity of $O(N^2)$ where $N$ is the number of landmarks in the map. Similarly the Maximum A Posteriori (MAP) estimator \cite{FULL-BA-BASED} has complexity of $O([K+N]^3)$, where $K$ is the number of robot poses in the map and $N$ as before is the number of landmarks in the map. Although existing MAP-based solvers for SLAM such as $\sqrt(SLAM)$ \cite{FULL-BA-BASED}, $g^2o$\cite{g2o} and SPA \cite{spaBYkonolige} efficiently exploit the sparsity in the problem to reduce complexity, large enough maps and frequent loop closures eventually render the algorithm inappropriate for real time operation.

It has already been introduced that the most popular methods for SLAM can broadly be divided into three categories. Approaches such as iSLAM \cite{Kaess08thesis} iSLAM2 \cite{Kaess01022012} incrementally solve an optimization problem containing all the robot poses along the trajectory, landmarks and measurements. Clearly the complexity in such approaches grows with time as the number of robot poses, landmarks and measurements increase. Although by exploiting sparsity, these methods can work for a reasonable period of time, frequent loop closures and prolonged usage eventually prohibits real-time operation of the algorithm. These approaches form the first category.

The second category of approaches such as the ones discussed in \cite {Sibley:2010, 4801600} have a fixed lag smoother in common. In this approach the computational cost is maintained constant by marginalizing the information from the frames outside the size of the sliding window. This makes the information matrix dense and hence the computational complexity becomes cubic in the number of poses considered in the window enforcing a rather small number of poses to be considered by the sliding window. More over since this approach is unable to loop close, it drifts faster than other methods. Often an offline BA algorithm is run to perform loop closure and to achieve globally consistent maps.

The third category of methods such as PTAM \cite{klein07parallel}, FrameSLAM \cite{4648456} and view based methods \cite {Konolige01072010, 6630556}, take the approach of key-framing. In this paradigm, the poses along the robot path are assigned either to be a key-frame or a non-key-frame. All the information available from the non-key-frames is discarded. Hence it is able to maintain sparsity, which lets it achieve higher computational efficiency at the cost of reduced accuracy. 

In \cite{CKLAM}, Esha D. Nerurkar et al. developed the `Constrained Key-frame Localization and Mapping' (CKLAM) technique. In this technique information from non-key-frames is marginalized while maintaining sparsity of information matrix. This way CKLAM achieves a higher computational performance and a higher map quality at the same time. In this thesis, a realization of this work has been achieved and it has been thoroughly tested with real and simulated maps. 

\section{Contributions}
Although CKLAM achieves the solution to some of the key problems faced in the large scale SLAM problem, it suffers from the following drawbacks. By projecting information from non-key-frame poses onto the key-frames, CKLAM generates expected mean pose, covariance and a gradient for every key-frame pair. This leads to a generation of constraints on the pose of key-frames in the global coordinate frame, which is not a drawback when an area is explored by a single agent. But in a multiple agent based mapping scenario, since the frame of reference of each agent is not aligned or they do not use same global frame it is necessary to change the frame of reference on the fly for large map segments. It also becomes necessary to recompute the CKLAM information at this point, if any such segment already had them. As CKLAM approximates the true cost function with a quadratic approximation, the trust region of convergence is limited. This imposes a constraint when loop closure constraints try to move a long drifting map segment by a large amount. It can be readily seen that the problem lies in the design of CKLAM - it tries to represent integrated noise/information as independent Gaussian distribution. Hence a better formulation of CKLAM would be to project the information from non-key-frames onto the relative transformation between the two consecutive key-frame poses rather than projecting them directly on the key-frame poses. 

The main contributions of this thesis work are as follows. In contrast to intractable full BA a key-frame based technique has been implemented. The technique in contrast to traditional approaches considers the information from non-key-frames. A few drawbacks as described above have been identified in the CKLAM formulation and an extension Relative CKLAM (RCKLAM) has been proposed which has been shown to overcome the problems identified. By design RCKLAM's computational complexity matches that of CKLAM. 

\section{Thesis Outline}
The contribution of this thesis can be broadly divided into two parts. First is the implementation of the CKLAM technique. In this context we shall establish a firm mathematical basis which we hope will make the work flow of CKLAM more intuitive to follow. Besides this, since the second contribution of this thesis builds on the concept of CKLAM, it would be easy to follow that as well. In chapter \ref {sec:CKLAM} we discuss the theory behind CKLAM and also derive the most important equations from the first principle. Here we also find the important issues with CKLAM that we would like to address. In chapter \ref{sec:RCKLAM}, we take a closer look at the foundation of Relative-CKLAM (RCKLAM) that is proposed in this theses to solve the problems identified in chapter \ref{sec:CKLAM}. Finally in chapter \ref{chap:ExptAndResults}, the results of different experiments on both real and simulated map are presented.
